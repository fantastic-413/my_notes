{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk3/lsp/miniconda3/envs/milvus/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前数据库： test_db\n",
      "当前数据库集合： ['hybrid_search_collection']\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader, UnstructuredExcelLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from pymilvus import (\n",
    "    connections,\n",
    "    utility,\n",
    "    FieldSchema, CollectionSchema, DataType,\n",
    "    Collection,\n",
    "    AnnSearchRequest, RRFRanker, WeightedRanker,\n",
    "    db\n",
    ")\n",
    "import numpy as np\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "from transformers import pipeline\n",
    "import os\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "\n",
    "from milvusdb import VectorDB\n",
    "\n",
    "devices = [\"cuda:1\"]\n",
    "MILVUS_HOST = \"localhost\"\n",
    "MILVUS_PORT = \"19530\"\n",
    "TARGET_DB = \"test_db\"  # 自定义数据库名称\n",
    "COLLECTION_NAME=\"hybrid_search_collection\"\n",
    "EMBEDDING_MODEL_PATH = \"/disk3/lsp/models/BAAI/bge-m3\"\n",
    "DIM = 1024\n",
    "\n",
    "# 连接 Milvus\n",
    "connections.connect(host=MILVUS_HOST, port=MILVUS_PORT)\n",
    "\n",
    "# 创建数据库（如果不存在）\n",
    "if TARGET_DB not in db.list_database():\n",
    "    print(f\"数据库 {TARGET_DB} 不存在，创建数据库\")\n",
    "    db.create_database(TARGET_DB)\n",
    "# 删除数据库\n",
    "# db.drop_database(TARGET_DB)\n",
    "\n",
    "# 切换当前数据库\n",
    "db.using_database(TARGET_DB)\n",
    "print(\"当前数据库：\", TARGET_DB)\n",
    "# 列出当前所有collection\n",
    "print(\"当前数据库集合：\", utility.list_collections())\n",
    "\n",
    "def drop_collection(collection_name):\n",
    "    if utility.has_collection(collection_name):\n",
    "        utility.drop_collection(collection_name)\n",
    "        print(f\"集合 {collection_name} 已删除\")\n",
    "    # for collection_name in utility.list_collections():\n",
    "    #     utility.drop_collection(collection_name)\n",
    "    #     print(f\"Collection {collection_name} dropped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXCEL文本解析与处理\n",
    "def extract_text_from_excel(excel_path):\n",
    "    print(f\"解析 Excel ：{excel_path}\")\n",
    "    loader = UnstructuredExcelLoader(excel_path)\n",
    "    data = loader.load()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredExcelLoader\n",
    "\n",
    "loader = UnstructuredExcelLoader(\"/disk3/lsp/milvus_test/excel/浙江一分一档表19-22.xlsx\", mode=\"elements\")\n",
    "docs = loader.load()\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.documents import Document\n",
    "# 读取excel文件\n",
    "df = pd.read_excel(\"/disk3/lsp/milvus_test/excel/浙江一分一档表19-22.xlsx\")\n",
    "data = df.to_string(index=False)\n",
    "docs = [Document(page_content=data, metadata={\"file_path\": \"/disk3/lsp/milvus_test/excel/浙江一分一档表19-22.xlsx\"})]\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "省份   年份 科类  分数  本段人数   累计人数\n",
      "浙江 2020 综合 715   352    352\n",
      "浙江 2020 综合 714   352    352\n",
      "浙江 2020 综合 713   352    352\n",
      "浙江 2020 综合 712   352    352\n",
      "浙江 2020 综合 711   352    352\n",
      "浙江 2020 综合 710   352    352\n",
      "浙江 2020 综合 709   352    352\n",
      "浙江 2020 综合 708   352    352\n",
      "浙江 2020 综合 707   352    352\n",
      "浙江 2020 综合 706   352    352\n",
      "浙江 2020 综合 705   352    352\n",
      "浙江 2020 综合 704   352    352\n",
      "浙江 2020 综合 703   352    352\n",
      "浙江 2020 综合 702   352    352\n",
      "浙江 2020 综合 701   352    352\n",
      "浙江 2020 综合 700   352    352\n",
      "浙江 2020 综合 699   352    352\n",
      "浙江 2020 综合 698   352    352\n",
      "浙江 2020 综合 697   352    352\n",
      "浙江 2020 综合 696   352    352\n",
      "浙江 2020 综合 695   352    352\n",
      "浙江 2020 综合 694   352    352\n",
      "浙江 2020 综合 693   352    352\n",
      "浙江 2020 综合 692   352    352\n",
      "浙江 2020 综合 691   352    352\n",
      "浙江 2021 综合 750   331    331\n",
      "浙江 2021 综合 749   331    331\n",
      "浙江 2021 综合 748   331    331\n",
      "浙江 2021 综合 747   331    331\n",
      "浙江 2021 综合 746   331    331\n",
      "浙江 2021 综合 745   331    331\n",
      "浙江 2021 综合 744   331    331\n",
      "浙江 2021 综合 743   331    331\n",
      "浙江 2021 综合 742   331    331\n",
      "浙江 2021 综合 741   331    331\n",
      "浙江 2021 综合 740   331    331\n"
     ]
    }
   ],
   "source": [
    "# 文本分割\n",
    "def split_documents(docs, chunk_size=1024, chunk_overlap=20):\n",
    "    \"\"\"使用LangChain的递归字符分割器\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \"。\", \"！\", \"？\", \"；\"]\n",
    "    )\n",
    "    \n",
    "    return text_splitter.split_documents(docs)\n",
    "\n",
    "chunks = split_documents(docs)\n",
    "texts = [doc.page_content for doc in chunks]\n",
    "# print(texts[0])\n",
    "# 提取纯列名行（第一行）\n",
    "header_line = data.split('\\n')[0] + '\\n'  # 带换行符\n",
    "texts = [header_line + text for text in texts]\n",
    "print(texts[41])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "省份: 浙江\n",
      "年份: 2019\n",
      "科类: 综合\n",
      "分数: 695\n",
      "本段人数: 32\n",
      "累计人数: 330\n",
      "多文档数量： 3000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 读取Excel并跳过\"序号\"列\n",
    "file_path = \"/disk3/lsp/milvus_test/excel/浙江一分一档表19-22.xlsx\"\n",
    "df = pd.read_excel(file_path)  # 修改\"序号\"为实际列名\n",
    "\n",
    "# 方法2：逐行生成多个Document（推荐用于检索场景）\n",
    "docs_multiple = []\n",
    "for _, row in df.iterrows():\n",
    "    content = \"\\n\".join([f\"{col}: {row[col]}\" for col in df.columns])\n",
    "    docs_multiple.append(Document(\n",
    "        page_content=content,\n",
    "        metadata={\"file_path\": file_path, \"columns\": list(df.columns)}\n",
    "    ))\n",
    "\n",
    "print(docs_multiple[0].page_content)\n",
    "print(\"多文档数量：\", len(docs_multiple))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "milvus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
